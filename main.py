import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules
import time

start = time.time()
# ------------------------------
# ðŸ“¥ Wczytywanie danych
# ------------------------------
df1 = pd.read_excel('zakupy-online.xlsx', sheet_name='Year 2009-2010')
df2 = pd.read_excel('zakupy-online.xlsx', sheet_name='Year 2010-2011')
df = pd.concat([df1, df2], ignore_index=True)

# ------------------------------
# ðŸ§¹ Czyszczenie danych
# ------------------------------
df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])
df = df[~df['Invoice'].astype(str).str.startswith('C')]
df = df.dropna()
df['TotalPrice'] = df['Quantity'] * df['Price']
df = df[(df['Quantity'] > 0) & (df['Price'] > 0) & (df['TotalPrice'] > 0)]
# ------------------------------
# ðŸ“Š Podstawowe statystyki zbioru
# ------------------------------
print("ðŸ“… Zakres dat:", df['InvoiceDate'].min(), "â†’", df['InvoiceDate'].max())
print("ðŸŒ Liczba krajÃ³w:", df['Country'].nunique())
print("ðŸŒ Lista krajÃ³w:", df['Country'].unique())
print("ðŸ“¦ Liczba unikalnych produktÃ³w:", df['StockCode'].nunique())
print("ðŸ§¾ Liczba unikalnych faktur:", df['Invoice'].nunique())
print("ðŸ‘¤ Liczba unikalnych klientÃ³w:", df['Customer ID'].nunique())

# ðŸ”„ ZmiennoÅ›Ä‡ sprzedaÅ¼y w czasie
sprzedaz_dzienna = df.groupby(df['InvoiceDate'].dt.date).agg({
    'Invoice': 'nunique',
    'TotalPrice': 'sum'
}).rename(columns={'Invoice': 'LiczbaTransakcji', 'TotalPrice': 'Sprzedaz'})

print("\nðŸ“ˆ SprzedaÅ¼ dzienna (pierwsze dni):\n", sprzedaz_dzienna.head())

# ðŸ† Najpopularniejsze produkty
top_produkty = df.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(10)
print("\nðŸ† Najpopularniejsze produkty:\n", top_produkty)

# ðŸ’° Najbardziej dochodowe produkty
top_przychod = df.groupby('Description')['TotalPrice'].sum().sort_values(ascending=False).head(10)
print("\nðŸ’° Najbardziej dochodowe produkty:\n", top_przychod)

# ------------------------------
# ðŸ” ANALIZA KOSZYKOWA PER KRAJ
# ------------------------------
kraje = df['Country'].unique()

for kraj in kraje:

    print(f"\n============================\nðŸŒ KRAJ: {kraj}\n============================")

    df_kraj = df[df['Country'] == kraj]

    if df_kraj.empty:
        print("âš ï¸ Brak danych dla tego kraju.")
        continue

    print("ðŸ“… Zakres dat:", df_kraj['InvoiceDate'].min(), "â†’", df_kraj['InvoiceDate'].max())
    print("ðŸ“¦ Liczba unikalnych produktÃ³w:", df_kraj['StockCode'].nunique())
    print("ðŸ§¾ Liczba unikalnych faktur:", df_kraj['Invoice'].nunique())
    print("ðŸ‘¤ Liczba unikalnych klientÃ³w:", df_kraj['Customer ID'].nunique())

    # ðŸ§º Macierz koszykowa (Invoice x Product)
    basket = df_kraj.groupby(['Invoice', 'Description'])['Quantity'].sum().unstack().fillna(0)
    basket = basket > 0

    if basket.empty or basket.shape[1] < 2:
        print("âš ï¸ Zbyt maÅ‚o danych do analizy koszykowej.")
        continue

    # ðŸ” Filtrowanie rzadkich produktÃ³w
    min_liczba_transakcji = 5
    product_counts = basket.sum()
    popularne_produkty = product_counts[product_counts >= min_liczba_transakcji]
    popularne_produkty = popularne_produkty.sort_values(ascending=False)

    # ðŸ”’ LIMIT: maksymalnie 500 najczÄ™stszych produktÃ³w
    popularne_produkty = popularne_produkty.head(2000).index
    basket = basket[popularne_produkty]

    if basket.shape[1] < 2:
        print("âš ï¸ Za maÅ‚o popularnych produktÃ³w w koszykach.")
        continue

    # ðŸ”¢ min_support = prÃ³g 20% najpopularniejszych
    product_freq = basket.sum().sort_values(ascending=False)
    threshold = product_freq.quantile(0.8)
    min_sup = threshold / basket.shape[0]
    print(f"ðŸ”¢ min_support (20% najpopularniejszych): {min_sup:.4f}")

    # ðŸ“˜ Zbiory czÄ™ste
    frequent_itemsets = apriori(basket, min_support=min_sup, use_colnames=True)
    frequent_itemsets = frequent_itemsets.sort_values(by='support', ascending=False)

    if frequent_itemsets.empty:
        print("âš ï¸ Brak zbiorÃ³w czÄ™stych.")
        continue

    print("ðŸ“˜ Zbiory czÄ™ste:\n", frequent_itemsets.head())

    # ðŸ“Ž ReguÅ‚y asocjacyjne
    rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.7)
    rules = rules.sort_values(by='confidence', ascending=False)

    if rules.empty:
        print("âš ï¸ Brak reguÅ‚ asocjacyjnych dla tego kraju.")
        continue

    print("ðŸ“ ReguÅ‚y asocjacyjne:\n", rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head())

end = time.time()

print(f"\nCzas wykonania: {end - start :.4f} sekund")